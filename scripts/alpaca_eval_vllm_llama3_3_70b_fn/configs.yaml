alpaca_eval_vllm_llama3_3_70b_fn:
  prompt_template: "alpaca_eval_vllm_llama3_3_70b_fn/alpaca_eval_fn.txt"
  fn_completions: "vllm_local_completions"
  completions_kwargs:
    model_name: "/home/shared/Meta-Llama-3.3-70B-Instruct"
    model_kwargs:
      tokenizer_mode: "auto"
      trust_remote_code: True
      max_model_len: 7000
      tp: 2
    max_new_tokens: 100
    temperature: 0.0
    top_p: 1.0
    batch_size: 900
  fn_completion_parser: "ranking_parser"
